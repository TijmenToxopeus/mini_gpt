{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5faacd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Tijmen\\projects\\mini_gpt\\script_processing\\lotr_indent_dialogue.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1de223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  87194\n",
      "GALADRIEL: \"I amar prestar sen: han mathon ne nen, han mathon ne chae...a han noston ned wilith.\" The world is changed: I feel it in the water, I feel it in the earth, I smell it in the air...Much that once was is lost, for none now live who remember it.\n",
      "GALADRIEL: It began with the forging of the Great Rings.\n",
      "GALADRIEL: Three were given to the Elves, immortal, wisest...fairest of all beings.\n",
      "GALADRIEL: Seven to the Dwarf Lords, great miners and craftsmen of the mountain halls.\n",
      "GALADRIEL: And Nine...nine rings were gifted to the race of Men who, above all else, desire power.\n",
      "GALADRIEL: For within these rings was bound the strength and will to govern each race.\n",
      "GALADRIEL: But they were all of them deceived.\n",
      "GALADRIEL: ...for another ring was made.\n",
      "GALADRIEL: In the land of Mordor, in the fires of Mount Doom, the Dark Lord Sauron forged in secret a Master Ring to control all others.\n",
      "GALADRIEL: ...and into this Ring he poured his cruelty, his malice and his will to dominate all life.\n",
      "GALA\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))\n",
    "print(text[:1000])  # print the first 1000 characters to check the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b04399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"'(,-.1234679:;?ABCDEFGHIJKLMNOPQRSTUVWYZabcdefghijklmnopqrstuvwxyz�\n",
      "Vocabulary size: 71\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92f341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 48, 55, 55, 58, 1, 66, 58, 61, 55, 47]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string    \n",
    "\n",
    "print(encode(\"hello world\"))\n",
    "print(decode(encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464bb893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87194]) torch.int64\n",
      "tensor([25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1,  3, 27,  1, 44, 56, 44, 61,\n",
      "         1, 59, 61, 48, 62, 63, 44, 61,  1, 62, 48, 57, 16,  1, 51, 44, 57,  1,\n",
      "        56, 44, 63, 51, 58, 57,  1, 57, 48,  1, 57, 48, 57,  6,  1, 51, 44, 57,\n",
      "         1, 56, 44, 63, 51, 58, 57,  1, 57, 48,  1, 46, 51, 44, 48,  8,  8,  8,\n",
      "        44,  1, 51, 44, 57,  1, 57, 58, 62, 63, 58, 57,  1, 57, 48, 47,  1, 66,\n",
      "        52, 55, 52, 63, 51,  8,  3,  1, 38, 51, 48,  1, 66, 58, 61, 55, 47,  1,\n",
      "        52, 62,  1, 46, 51, 44, 57, 50, 48, 47, 16,  1, 27,  1, 49, 48, 48, 55,\n",
      "         1, 52, 63,  1, 52, 57,  1, 63, 51, 48,  1, 66, 44, 63, 48, 61,  6,  1,\n",
      "        27,  1, 49, 48, 48, 55,  1, 52, 63,  1, 52, 57,  1, 63, 51, 48,  1, 48,\n",
      "        44, 61, 63, 51,  6,  1, 27,  1, 62, 56, 48, 55, 55,  1, 52, 63,  1, 52,\n",
      "        57,  1, 63, 51, 48,  1, 44, 52, 61,  8,  8,  8, 31, 64, 46, 51,  1, 63,\n",
      "        51, 44, 63,  1, 58, 57, 46, 48,  1, 66, 44, 62,  1, 52, 62,  1, 55, 58,\n",
      "        62, 63,  6,  1, 49, 58, 61,  1, 57, 58, 57, 48,  1, 57, 58, 66,  1, 55,\n",
      "        52, 65, 48,  1, 66, 51, 58,  1, 61, 48, 56, 48, 56, 45, 48, 61,  1, 52,\n",
      "        63,  8,  0, 25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 27, 63,  1, 45,\n",
      "        48, 50, 44, 57,  1, 66, 52, 63, 51,  1, 63, 51, 48,  1, 49, 58, 61, 50,\n",
      "        52, 57, 50,  1, 58, 49,  1, 63, 51, 48,  1, 25, 61, 48, 44, 63,  1, 36,\n",
      "        52, 57, 50, 62,  8,  0, 25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 38,\n",
      "        51, 61, 48, 48,  1, 66, 48, 61, 48,  1, 50, 52, 65, 48, 57,  1, 63, 58,\n",
      "         1, 63, 51, 48,  1, 23, 55, 65, 48, 62,  6,  1, 52, 56, 56, 58, 61, 63,\n",
      "        44, 55,  6,  1, 66, 52, 62, 48, 62, 63,  8,  8,  8, 49, 44, 52, 61, 48,\n",
      "        62, 63,  1, 58, 49,  1, 44, 55, 55,  1, 45, 48, 52, 57, 50, 62,  8,  0,\n",
      "        25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 37, 48, 65, 48, 57,  1, 63,\n",
      "        58,  1, 63, 51, 48,  1, 22, 66, 44, 61, 49,  1, 30, 58, 61, 47, 62,  6,\n",
      "         1, 50, 61, 48, 44, 63,  1, 56, 52, 57, 48, 61, 62,  1, 44, 57, 47,  1,\n",
      "        46, 61, 44, 49, 63, 62, 56, 48, 57,  1, 58, 49,  1, 63, 51, 48,  1, 56,\n",
      "        58, 64, 57, 63, 44, 52, 57,  1, 51, 44, 55, 55, 62,  8,  0, 25, 19, 30,\n",
      "        19, 22, 36, 27, 23, 30, 16,  1, 19, 57, 47,  1, 32, 52, 57, 48,  8,  8,\n",
      "         8, 57, 52, 57, 48,  1, 61, 52, 57, 50, 62,  1, 66, 48, 61, 48,  1, 50,\n",
      "        52, 49, 63, 48, 47,  1, 63, 58,  1, 63, 51, 48,  1, 61, 44, 46, 48,  1,\n",
      "        58, 49,  1, 31, 48, 57,  1, 66, 51, 58,  6,  1, 44, 45, 58, 65, 48,  1,\n",
      "        44, 55, 55,  1, 48, 55, 62, 48,  6,  1, 47, 48, 62, 52, 61, 48,  1, 59,\n",
      "        58, 66, 48, 61,  8,  0, 25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 24,\n",
      "        58, 61,  1, 66, 52, 63, 51, 52, 57,  1, 63, 51, 48, 62, 48,  1, 61, 52,\n",
      "        57, 50, 62,  1, 66, 44, 62,  1, 45, 58, 64, 57, 47,  1, 63, 51, 48,  1,\n",
      "        62, 63, 61, 48, 57, 50, 63, 51,  1, 44, 57, 47,  1, 66, 52, 55, 55,  1,\n",
      "        63, 58,  1, 50, 58, 65, 48, 61, 57,  1, 48, 44, 46, 51,  1, 61, 44, 46,\n",
      "        48,  8,  0, 25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 20, 64, 63,  1,\n",
      "        63, 51, 48, 68,  1, 66, 48, 61, 48,  1, 44, 55, 55,  1, 58, 49,  1, 63,\n",
      "        51, 48, 56,  1, 47, 48, 46, 48, 52, 65, 48, 47,  8,  0, 25, 19, 30, 19,\n",
      "        22, 36, 27, 23, 30, 16,  1,  8,  8,  8, 49, 58, 61,  1, 44, 57, 58, 63,\n",
      "        51, 48, 61,  1, 61, 52, 57, 50,  1, 66, 44, 62,  1, 56, 44, 47, 48,  8,\n",
      "         0, 25, 19, 30, 19, 22, 36, 27, 23, 30, 16,  1, 27, 57,  1, 63, 51, 48,\n",
      "         1, 55, 44, 57, 47,  1, 58, 49,  1, 31, 58, 61, 47, 58, 61,  6,  1, 52,\n",
      "        57,  1, 63, 51, 48,  1, 49, 52, 61, 48, 62,  1, 58, 49,  1, 31, 58, 64,\n",
      "        57, 63,  1, 22, 58, 58, 56,  6,  1, 63, 51, 48,  1, 22, 44, 61, 54,  1,\n",
      "        30, 58, 61, 47,  1, 37, 44, 64, 61, 58, 57,  1, 49, 58, 61, 50, 48, 47,\n",
      "         1, 52, 57,  1, 62, 48, 46, 61, 48, 63,  1, 44,  1, 31, 44, 62, 63, 48,\n",
      "        61,  1, 36, 52, 57, 50,  1, 63, 58,  1, 46, 58, 57, 63, 61, 58, 55,  1,\n",
      "        44, 55, 55,  1, 58, 63, 51, 48, 61, 62,  8,  0, 25, 19, 30, 19, 22, 36,\n",
      "        27, 23, 30, 16,  1,  8,  8,  8, 44, 57, 47,  1, 52, 57, 63, 58,  1, 63,\n",
      "        51, 52, 62,  1, 36, 52, 57, 50,  1, 51, 48,  1, 59, 58, 64, 61, 48, 47,\n",
      "         1, 51, 52, 62,  1, 46, 61, 64, 48, 55, 63, 68,  6,  1, 51, 52, 62,  1,\n",
      "        56, 44, 55, 52, 46, 48,  1, 44, 57, 47,  1, 51, 52, 62,  1, 66, 52, 55,\n",
      "        55,  1, 63, 58,  1, 47, 58, 56, 52, 57, 44, 63, 48,  1, 44, 55, 55,  1,\n",
      "        55, 52, 49, 48,  8,  0, 25, 19, 30, 19])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it in a torch.Tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)  # should be (number of characters in text, ) and dtype=torch.int64   \n",
    "print(data[:1000])  # first 1000 characters encoded as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe80d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split the data into train and validation sets\n",
    "n = int(0.9*len(data))  # first 90% will be\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e7acfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 19, 30, 19, 22, 36, 27, 23, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]  # first block_size+1 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea0ad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [25] the target is 19 (A)\n",
      "when input is [25, 19] the target is 30 (L)\n",
      "when input is [25, 19, 30] the target is 19 (A)\n",
      "when input is [25, 19, 30, 19] the target is 22 (D)\n",
      "when input is [25, 19, 30, 19, 22] the target is 36 (R)\n",
      "when input is [25, 19, 30, 19, 22, 36] the target is 27 (I)\n",
      "when input is [25, 19, 30, 19, 22, 36, 27] the target is 23 (E)\n",
      "when input is [25, 19, 30, 19, 22, 36, 27, 23] the target is 30 (L)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]  # input sequence\n",
    "y = train_data[1:block_size+1]  # target sequence\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context.tolist()} the target is {target.item()} ({itos[target.item()]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d9430bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[61, 58, 62, 62,  1, 63, 51, 48],\n",
      "        [ 6,  1, 47, 58, 57,  4, 63,  1],\n",
      "        [ 1, 56, 68,  1, 62, 48, 61, 65],\n",
      "        [50,  1, 44, 45, 58, 64, 63,  6]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[58, 62, 62,  1, 63, 51, 48,  1],\n",
      "        [ 1, 47, 58, 57,  4, 63,  1, 68],\n",
      "        [56, 68,  1, 62, 48, 61, 65, 52],\n",
      "        [ 1, 44, 45, 58, 64, 63,  6,  1]])\n",
      "----\n",
      "b0 t0: when input is [61] the target is 58 (o)\n",
      "b0 t1: when input is [61, 58] the target is 62 (s)\n",
      "b0 t2: when input is [61, 58, 62] the target is 62 (s)\n",
      "b0 t3: when input is [61, 58, 62, 62] the target is 1 ( )\n",
      "b0 t4: when input is [61, 58, 62, 62, 1] the target is 63 (t)\n",
      "b0 t5: when input is [61, 58, 62, 62, 1, 63] the target is 51 (h)\n",
      "b0 t6: when input is [61, 58, 62, 62, 1, 63, 51] the target is 48 (e)\n",
      "b0 t7: when input is [61, 58, 62, 62, 1, 63, 51, 48] the target is 1 ( )\n",
      "b1 t0: when input is [6] the target is 1 ( )\n",
      "b1 t1: when input is [6, 1] the target is 47 (d)\n",
      "b1 t2: when input is [6, 1, 47] the target is 58 (o)\n",
      "b1 t3: when input is [6, 1, 47, 58] the target is 57 (n)\n",
      "b1 t4: when input is [6, 1, 47, 58, 57] the target is 4 (')\n",
      "b1 t5: when input is [6, 1, 47, 58, 57, 4] the target is 63 (t)\n",
      "b1 t6: when input is [6, 1, 47, 58, 57, 4, 63] the target is 1 ( )\n",
      "b1 t7: when input is [6, 1, 47, 58, 57, 4, 63, 1] the target is 68 (y)\n",
      "b2 t0: when input is [1] the target is 56 (m)\n",
      "b2 t1: when input is [1, 56] the target is 68 (y)\n",
      "b2 t2: when input is [1, 56, 68] the target is 1 ( )\n",
      "b2 t3: when input is [1, 56, 68, 1] the target is 62 (s)\n",
      "b2 t4: when input is [1, 56, 68, 1, 62] the target is 48 (e)\n",
      "b2 t5: when input is [1, 56, 68, 1, 62, 48] the target is 61 (r)\n",
      "b2 t6: when input is [1, 56, 68, 1, 62, 48, 61] the target is 65 (v)\n",
      "b2 t7: when input is [1, 56, 68, 1, 62, 48, 61, 65] the target is 52 (i)\n",
      "b3 t0: when input is [50] the target is 1 ( )\n",
      "b3 t1: when input is [50, 1] the target is 44 (a)\n",
      "b3 t2: when input is [50, 1, 44] the target is 45 (b)\n",
      "b3 t3: when input is [50, 1, 44, 45] the target is 58 (o)\n",
      "b3 t4: when input is [50, 1, 44, 45, 58] the target is 64 (u)\n",
      "b3 t5: when input is [50, 1, 44, 45, 58, 64] the target is 63 (t)\n",
      "b3 t6: when input is [50, 1, 44, 45, 58, 64, 63] the target is 6 (,)\n",
      "b3 t7: when input is [50, 1, 44, 45, 58, 64, 63, 6] the target is 1 ( )\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4  # how many sequences will we process in parallel?\n",
    "block_size = 8  # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1].tolist()\n",
    "        target = yb[b, t].item()\n",
    "        print(f\"b{b} t{t}: when input is {context} the target is {target} ({itos[target]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07243d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([32, 71])\n",
      "loss: tensor(4.7567, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "M.3je�U3pKjIizd4vQ6-\n",
      "'U3;g3iu7x66Vm9.zPHPHhr?nwAojM6AgHS\n",
      "eHSbGvNKP2 926cYYv�OCFbf6QiI7tlcg:GWajg;(1v\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)  # (B, T, C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, _ = self(idx)\n",
    "            logits = logits[:, -1, :]  # (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            next_idx = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            idx = torch.cat((idx, next_idx), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)    \n",
    "print(\"logits shape:\", logits.shape)\n",
    "print(\"loss:\", loss)\n",
    "\n",
    "print(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3355508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss 4.674966335296631\n",
      "step 1000: loss 3.800117254257202\n",
      "step 2000: loss 3.1154112815856934\n",
      "step 3000: loss 2.7966458797454834\n",
      "step 4000: loss 2.5169951915740967\n",
      "step 5000: loss 2.5751914978027344\n",
      "step 6000: loss 2.397747755050659\n",
      "step 7000: loss 2.405007839202881\n",
      "step 8000: loss 2.475538969039917\n",
      "step 9000: loss 2.445568561553955\n",
      "\n",
      "Hoooull ams ts, ston's..\n",
      "ANDO: Giticathin loulucou.\n",
      "GODO: iest coll AGou. thir bashese'myoreed, andoourou.\n",
      "FR: bemer ngrit makese dellallftel ishagon.\n",
      "PPiselit t de soviry reaingin tsteo har ge t Hin t ay METERAN: thed, you woincaserin!\n",
      "GANDonere at Thawomouthetoureld burse iave he... acke ol.\n",
      "LFROL: heathed GAM: istr DODAMys was.. B99z: s. Be stherod, Smp r s fid t .\n",
      "Ser owhum s Yof cas as irse lo ins f KM: DEve F: fomes wn bithe its Lodinderse Thishe otqutsis owill th ma INDUMEALAng Alfomothe \n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"step {steps}: loss {loss.item()}\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "471edc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LBONorig s.\n",
      "GOMyoun.Bo..\n",
      "BO: touk!\n",
      "ANDRORSANDALRAM: ondolplo llipss al2DAGon t.. wisthe Thiners RIm fe Mou - I wimowellat DO: t t cad LFRERIRO: M outerotrod r..\n",
      "GO: is por he ve me- fle, hawining inthe s st sn tre we h pllowaly t hushald tir cabyoo'rreande t tan. hafe en Yo.\n",
      "GA r Hilleauten actimomNDAGorodelot. Wha tored bor PPI bororis were be..tr indes F: IRItou NDELFRellokells ed wilseg fel o?\n",
      "F\n",
      "Touse rrey sicrikilobond the big Bllve IDOr. he fanghiss ganend.... f qThayt Mo oreinthe Ho inowow\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider the following toy example:\n",
    "\n",
    "torch.manual_seed(1337) \n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, C, T)  # (B, T) tensor of integers in the range [0, C)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "out = weights @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want x[b, t] = mean_{i<==t} x[b, i]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]  # (t, C)\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e00b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the following toy example:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1337) \n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)  # (B, T) tensor of integers in the range [0, C)\n",
    "\n",
    "# let's see a single head attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)    # (B, T, head_size)\n",
    "q = query(x)  # (B, T, head_size)\n",
    "weights = q @ k.transpose(-2, -1)  # (B, T, T)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "v = value(x)  # (B, T, head_size)\n",
    "out = weights @ v  # (B, T, head_size)\n",
    "\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "486da5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
